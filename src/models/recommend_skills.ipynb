{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('../../data/raw/revisioned_first_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Skills Required'] = dataset['Skills Required'].str.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['Job Role Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = input(\"Enter a job role: \")\n",
    "exact_match = dataset[dataset['Job Role Title'].str.lower() == user_input.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar job roles found:\n",
      "Job Role: Data Analyst\n",
      "Skills: SQL,  Excel,  Data Visualization,  Statistics,  Data Cleaning,  Tableau,  Power BI \n",
      "\n",
      "Job Role: Business Intelligence Analyst\n",
      "Skills: SQL,  Tableau,  Power BI,  Data Visualization,  Business Analysis,  Data Reporting \n",
      "\n",
      "Job Role: Senior Data Analyst\n",
      "Skills: SQL,  Excel,  Tableau,  Data Visualization,  Data Cleaning,  Data Analysis \n",
      "\n",
      "Job Role: Big Data Analyst\n",
      "Skills: Hadoop,  Spark,  Python,  SQL,  Data Visualization,  ETL \n",
      "\n",
      "Job Role: Data Analyst II\n",
      "Skills: SQL,  Excel,  Tableau,  Power BI,  Data Visualization,  Data Cleaning \n",
      "\n",
      "Job Role: Data Analyst\n",
      "Skills: SQL,  Excel,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI,  Data Cleaning \n",
      "\n",
      "Job Role: Big Data Analyst\n",
      "Skills: Data Analysis,  Hadoop,  Spark,  Python,  SQL,  Data Visualization,  Data Cleaning,  Statistical Analysis \n",
      "\n",
      "Job Role: Data Science Intern\n",
      "Skills: Python,  R,  Data Analysis,  Statistical Analysis,  Data Visualization,  Machine Learning,  SQL,  Data Cleaning \n",
      "\n",
      "Job Role: Junior Data Analyst\n",
      "Skills: SQL,  Excel,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI,  Data Cleaning \n",
      "\n",
      "Job Role: Machine Learning Intern\n",
      "Skills: Machine Learning,  Python,  TensorFlow,  PyTorch,  Data Preprocessing,  Model Evaluation,  Data Analysis \n",
      "\n",
      "Job Role: Data Governance Analyst\n",
      "Skills: Data Governance,  Data Management,  Data Quality,  Data Policies,  Data Stewardship,  SQL \n",
      "\n",
      "Job Role: Data Engineering Intern\n",
      "Skills: SQL,  ETL,  Python,  Hadoop,  Spark,  AWS,  Azure,  Data Warehousing,  NoSQL,  Data Integration \n",
      "\n",
      "Job Role: Big Data Analyst II\n",
      "Skills: Data Analysis,  Hadoop,  Spark,  Python,  SQL,  Data Visualization,  Data Cleaning,  Statistical Analysis \n",
      "\n",
      "Job Role: Data Quality Analyst\n",
      "Skills: Data Quality Assurance,  Data Validation,  Data Cleansing,  SQL,  Data Profiling,  Data Governance \n",
      "\n",
      "Job Role: Big Data Performance Analyst\n",
      "Skills: Hadoop Performance,  Spark Performance,  Optimization,  Monitoring,  Troubleshooting,  Benchmarking \n",
      "\n",
      "Job Role: Data Engineering Intern II\n",
      "Skills: SQL,  ETL,  Python,  Hadoop,  Spark,  AWS,  Azure,  Data Warehousing,  NoSQL,  Data Integration \n",
      "\n",
      "Job Role: Big Data Analyst III\n",
      "Skills: Data Analysis,  Hadoop,  Spark,  Python,  SQL,  Data Visualization,  Data Cleaning,  Statistical Analysis \n",
      "\n",
      "Job Role: Data Governance Analyst II\n",
      "Skills: Data Governance,  Data Management,  Data Quality,  Data Policies,  Data Stewardship,  SQL,  Compliance \n",
      "\n",
      "Job Role: Big Data Performance Analyst II\n",
      "Skills: Hadoop Performance,  Spark Performance,  Optimization,  Monitoring,  Troubleshooting,  Benchmarking \n",
      "\n",
      "Job Role: Data Engineering Intern III\n",
      "Skills: SQL,  ETL,  Python,  Hadoop,  Spark,  AWS,  Azure,  Data Warehousing,  NoSQL,  Data Integration \n",
      "\n",
      "Job Role: Big Data Analyst IV\n",
      "Skills: Data Analysis,  Hadoop,  Spark,  Python,  SQL,  Data Visualization,  Data Cleaning,  Statistical Analysis,  Leadership \n",
      "\n",
      "Job Role: Data Analyst II\n",
      "Skills: SQL,  Excel,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI,  Data Cleaning \n",
      "\n",
      "Job Role: Big Data Analyst II\n",
      "Skills: Data Analysis,  Hadoop,  Spark,  Python,  SQL,  Data Visualization,  Data Cleaning,  Statistical Analysis \n",
      "\n",
      "Job Role: Data Science Intern II\n",
      "Skills: Python,  R,  Data Analysis,  Statistical Analysis,  Data Visualization,  Machine Learning,  SQL,  Data Cleaning \n",
      "\n",
      "Job Role: Junior Data Analyst II\n",
      "Skills: SQL,  Excel,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI,  Data Cleaning \n",
      "\n",
      "Job Role: Machine Learning Intern II\n",
      "Skills: Machine Learning,  Python,  TensorFlow,  PyTorch,  Data Preprocessing,  Model Evaluation,  Data Analysis \n",
      "\n",
      "Job Role: Data Analyst III\n",
      "Skills: SQL,  Excel,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI,  Data Cleaning \n",
      "\n",
      "Job Role: Big Data Analyst III\n",
      "Skills: Data Analysis,  Hadoop,  Spark,  Python,  SQL,  Data Visualization,  Data Cleaning,  Statistical Analysis \n",
      "\n",
      "Job Role: Data Science Intern III\n",
      "Skills: Python,  R,  Data Analysis,  Statistical Analysis,  Data Visualization,  Machine Learning,  SQL,  Data Cleaning \n",
      "\n",
      "Job Role: Junior Data Analyst III\n",
      "Skills: SQL,  Excel,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI,  Data Cleaning \n",
      "\n",
      "Job Role: Machine Learning Intern III\n",
      "Skills: Machine Learning,  Python,  TensorFlow,  PyTorch,  Data Preprocessing,  Model Evaluation,  Data Analysis \n",
      "\n",
      "Job Role: Data Analyst\n",
      "Skills: Data Analysis,  SQL,  Excel,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI \n",
      "\n",
      "Job Role: Business Intelligence Analyst\n",
      "Skills: Business Intelligence,  Data Analysis,  Data Visualization,  SQL,  Business Intelligence Tools,  Reporting,  Dashboard Creation \n",
      "\n",
      "Job Role: Big Data Quality Analyst\n",
      "Skills: Data Testing,  Quality Assurance,  Hadoop,  Spark,  SQL,  ETL,  Big Data Technologies,  Test Automation \n",
      "\n",
      "Job Role: Data Insights Analyst\n",
      "Skills: Data Analysis,  SQL,  Data Visualization,  Statistical Analysis,  Python,  R,  Tableau,  Power BI,  Data Interpretation \n",
      "\n",
      "Job Role: Security Analyst\n",
      "Skills: Cybersecurity,  Network Security,  Security Incident Response,  SIEM Tools,  Firewall Management,  Threat Detection,  Security Policies \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not exact_match.empty:\n",
    "    print(\"Exact match found!\")\n",
    "    print(f\"Job Role: {exact_match['Job Role Title'].values[0]}\")\n",
    "    print(f\"Skills: {', '.join(exact_match['Skills Required'].values[0])}\")\n",
    "else:\n",
    "    user_input_vector = tfidf_vectorizer.transform([user_input])\n",
    "    similarities = cosine_similarity(user_input_vector, tfidf_matrix)\n",
    "    threshold = 0.2\n",
    "\n",
    "    similar_roles = dataset[similarities[0] > threshold]\n",
    "\n",
    "    if not similar_roles.empty:\n",
    "        print(\"Similar job roles found:\")\n",
    "        for index, row in similar_roles.iterrows():\n",
    "            print(f\"Job Role: {row['Job Role Title']}\")\n",
    "            print(f\"Skills: {', '.join(row['Skills Required'])} \\n\")\n",
    "    else:\n",
    "        print(\"No matching job roles found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we used several concepts and libraries for the task of finding job roles based on user input and then displaying the combined skills for those roles. Here are the key concepts and libraries used:\n",
    "\n",
    "1. **Pandas:** We used the Pandas library to load and manipulate the dataset stored in a CSV file. Pandas provides data structures and functions for data analysis and manipulation, making it easy to work with tabular data.\n",
    "\n",
    "2. **NLP (Natural Language Processing):** NLP concepts are used for tokenizing and processing text data. In particular, we tokenized the job roles, user input, and skills to work with text-based information.\n",
    "\n",
    "3. **TF-IDF (Term Frequency-Inverse Document Frequency):** We used TF-IDF vectorization to represent the job roles as numerical vectors. This technique is commonly used in text mining and information retrieval to convert text data into a numerical format for similarity calculations.\n",
    "\n",
    "4. **Cosine Similarity:** Cosine similarity is a metric used to determine how similar two vectors (in our case, job roles) are in a high-dimensional space. We calculated the cosine similarity between job roles to identify similar job roles based on their textual content.\n",
    "\n",
    "5. **Data Preprocessing:** We preprocessed the dataset by splitting the skills in each job role into a list. This allowed us to work with individual skills for each role.\n",
    "\n",
    "6. **Matching and Filtering:** We matched user input against job roles based on common words or tokens. If at least one word from the user input matched with any word in a job role, we considered it a match.\n",
    "\n",
    "7. **Thresholding:** We applied a similarity threshold to filter out job roles that are considered similar based on the cosine similarity scores.\n",
    "\n",
    "8. **Data Structures:** We used Python dictionaries and sets to organize and store information. Dictionaries were used to map job roles to their corresponding skills, and sets were used to combine and store unique skills.\n",
    "\n",
    "9. **Looping and Iteration:** We used loops to iterate through job roles and their similarities, as well as to iterate through tokens in the user input.\n",
    "\n",
    "10. **Conditional Statements:** We used conditional statements to filter and display the results, such as showing the combined skills for matched job roles.\n",
    "\n",
    "These concepts and libraries were combined to create a program that takes user input, finds matching job roles, identifies similar roles, and displays the combined skills for those roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# dataset = pd.read_csv('../../data/raw/revisioned_first_set.csv')\n",
    "\n",
    "# job_roles = dataset['Job Role Title'].tolist()\n",
    "# skills = dataset['Skills Required'].tolist()\n",
    "\n",
    "# job_skill_dict = {role: skill.split(\", \") for role, skill in zip(job_roles, skills)}\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(job_roles)\n",
    "# cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# similarity_threshold = 0.6\n",
    "\n",
    "# similar_roles = {}\n",
    "# for i, role in enumerate(job_roles):\n",
    "#     similar_roles[role] = [job_roles[j] for j, sim in enumerate(cosine_sim[i]) if i != j and sim >= similarity_threshold]\n",
    "\n",
    "# combined_skills = {}\n",
    "# for role, similar in similar_roles.items():\n",
    "#     combined_skills[role] = set(job_skill_dict[role])\n",
    "#     for similar_role in similar:\n",
    "#         combined_skills[role].update(job_skill_dict[similar_role])\n",
    "\n",
    "# # user_input = \"Data Scientist\"\n",
    "# user_input = input(\"Enter your job role: \")\n",
    "\n",
    "# user_tokens = user_input.split()\n",
    "\n",
    "# matched_roles = []\n",
    "\n",
    "# for role in job_roles:\n",
    "#     role_tokens = role.split()\n",
    "#     for token in user_tokens:\n",
    "#         if token in role_tokens:\n",
    "#             matched_roles.append(role)\n",
    "#             break\n",
    "\n",
    "# if matched_roles:\n",
    "#     for role in matched_roles:\n",
    "#         print(f\"Job Role: {role}\")\n",
    "#         print(f\"Combined Skills: {', '.join(combined_skills[role])} \\n\")\n",
    "# else:\n",
    "#     print(\"No matching job roles found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
